# ğŸš€ ETL Pipeline Demo Project

Dá»± Ã¡n demo Ä‘Æ¡n giáº£n Ä‘á»ƒ há»c Data Engineering - ETL Pipeline vá»›i Docker

## ğŸ“– Tá»•ng Quan

ÄÃ¢y lÃ  má»™t dá»± Ã¡n demo hoÃ n chá»‰nh Ä‘á»ƒ hiá»ƒu vá»:

- **ETL Pipeline**: Extract, Transform, Load
- **Data Processing**: LÃ m sáº¡ch, validate, enrich dá»¯ liá»‡u
- **Data Storage**: Data Warehouse (PostgreSQL) vÃ  Data Lake (file system)
- **Orchestration**: Quáº£n lÃ½ workflow vÃ  scheduling
- **Visualization**: Dashboard vÃ  BI tools
- **Containerization**: Docker setup cho toÃ n bá»™ project

### Use Case: E-commerce Sales Pipeline

Xá»­ lÃ½ dá»¯ liá»‡u bÃ¡n hÃ ng tá»« nhiá»u nguá»“n:
- **Orders CSV**: ThÃ´ng tin Ä‘Æ¡n hÃ ng
- **Customers JSON**: ThÃ´ng tin khÃ¡ch hÃ ng
- **Products JSON**: ThÃ´ng tin sáº£n pháº©m

Pipeline sáº½:
1. Extract dá»¯ liá»‡u tá»« CSV, JSON
2. Validate vÃ  clean data
3. Transform (join, enrich, calculate revenue)
4. Load vÃ o PostgreSQL (Data Warehouse) vÃ  Parquet files (Data Lake)
5. Visualize trÃªn Dashboard

## ğŸ—ï¸ Kiáº¿n TrÃºc

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Source â”‚  (CSV, JSON files)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Extract   â”‚  (TrÃ­ch xuáº¥t dá»¯ liá»‡u)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Transform/   â”‚  (Validate, Clean, Enrich)
â”‚  Process   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Load     â”‚  (Data Warehouse + Data Lake)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Analytics  â”‚  (Dashboard, Notebooks, Reports)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Cáº¥u TrÃºc Project

```
etl/
â”œâ”€â”€ README.md                 # File nÃ y
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ Dockerfile                # Docker image definition
â”œâ”€â”€ docker-compose.yml        # Docker services orchestration (with live code mounting)
â”œâ”€â”€ .env.example              # Environment variables template
â”œâ”€â”€ .gitignore                # Git ignore rules
â”‚
â”œâ”€â”€ src/                      # Source code
â”‚   â”œâ”€â”€ extract/              # Data extraction
â”‚   â”‚   â”œâ”€â”€ csv_extractor.py
â”‚   â”‚   â”œâ”€â”€ json_extractor.py
â”‚   â”‚   â””â”€â”€ api_extractor.py
â”‚   â”œâ”€â”€ transform/            # Data transformation
â”‚   â”‚   â”œâ”€â”€ validator.py      # Data validation
â”‚   â”‚   â”œâ”€â”€ cleaner.py        # Data cleaning
â”‚   â”‚   â””â”€â”€ transformer.py    # Data transformation
â”‚   â”œâ”€â”€ load/                 # Data loading
â”‚   â”‚   â””â”€â”€ loader.py         # Database & file loader
â”‚   â”œâ”€â”€ utils/                # Utilities
â”‚   â”‚   â”œâ”€â”€ database.py       # Database connection
â”‚   â”‚   â””â”€â”€ logger.py         # Logging
â”‚   â”œâ”€â”€ pipeline.py           # Main ETL pipeline
â”‚   â””â”€â”€ dashboard.py          # Dashboard backend
â”‚
â”œâ”€â”€ config/                   # Configuration files
â”‚   â””â”€â”€ config.yaml           # Pipeline configuration
â”‚
â”œâ”€â”€ data/                     # Data storage
â”‚   â”œâ”€â”€ raw/                  # Raw data (from sources)
â”‚   â”œâ”€â”€ processed/           # Processed data (after transform)
â”‚   â””â”€â”€ sample/              # Sample data for testing
â”‚
â”œâ”€â”€ scripts/                  # Utility scripts
â”‚   â”œâ”€â”€ setup_db.py          # Database schema setup
â”‚   â”œâ”€â”€ run_pipeline.py      # Pipeline runner
â”‚   â”œâ”€â”€ docker_setup.sh      # Docker setup script
â”‚   â””â”€â”€ run_dashboard.sh      # Dashboard runner
â”‚
â”œâ”€â”€ notebooks/                # Jupyter notebooks
â”‚   â”œâ”€â”€ analysis.ipynb       # Data analysis
â”‚   â””â”€â”€ data_exploration.ipynb
â”‚
â”œâ”€â”€ logs/                     # Log files (gitignored)
â”‚
â””â”€â”€ tests/                   # Unit tests
```

## ğŸš€ Quick Start

### Prerequisites

- **Docker** vÃ  **Docker Compose** (V2) - Báº¯t buá»™c
- Git (optional)

**âš ï¸ LÆ°u Ã½**: Project nÃ y sá»­ dá»¥ng Docker Ä‘á»ƒ cháº¡y táº¥t cáº£ services. KhÃ´ng cáº§n cÃ i Ä‘áº·t Python, PostgreSQL trÃªn mÃ¡y local.

### Option 1: Docker Setup (Recommended) ğŸ³

Táº¥t cáº£ services (PostgreSQL, Dashboard, Jupyter) cháº¡y trong Docker containers.

#### 1. Clone repository (náº¿u cÃ³)

```bash
git clone <repository-url>
cd etl
```

#### 2. Setup tá»± Ä‘á»™ng

```bash
# Make script executable
chmod +x scripts/docker_setup.sh

# Run setup script (sáº½ tá»± Ä‘á»™ng setup táº¥t cáº£)
./scripts/docker_setup.sh
```

Script nÃ y sáº½:
- âœ… Táº¡o `.env` file náº¿u chÆ°a cÃ³
- âœ… Build Docker images
- âœ… Start PostgreSQL vÃ  setup database schema
- âœ… Start táº¥t cáº£ services (Dashboard, Jupyter)

#### 3. Access services

Sau khi setup xong:

- **Dashboard**: http://localhost:8501
- **Jupyter Lab**: http://localhost:8888
- **PostgreSQL**: localhost:5432

#### 4. Run Pipeline

```bash
# Cháº¡y pipeline tá»« Dashboard (recommended)
# Má»Ÿ http://localhost:8501 â†’ Chá»n "ğŸš€ Run Pipeline"

# Hoáº·c cháº¡y tá»« command line
docker compose run --rm pipeline python scripts/run_pipeline.py
```

### Option 2: Local Development

Náº¿u muá»‘n cháº¡y trÃªn mÃ¡y local (khÃ´ng dÃ¹ng Docker):

#### 1. Setup Python environment

```bash
# Táº¡o virtual environment
python -m venv venv
source venv/bin/activate  # macOS/Linux
# hoáº·c venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt
```

#### 2. Setup PostgreSQL vá»›i Docker

```bash
# Start PostgreSQL container
docker compose up -d postgres

# Setup database schema
python scripts/setup_db.py
```

#### 3. Create `.env` file

```bash
# Copy template
cp .env.example .env

# Edit .env vÃ  update DB_HOST=localhost (thay vÃ¬ postgres)
```

#### 4. Run services

```bash
# Run dashboard
streamlit run dashboard.py

# Run Jupyter (in another terminal)
jupyter lab
```

## ğŸ”¨ Build

### Build Docker Images

```bash
# Build all services
docker compose build

# Build specific service
docker compose build dashboard
docker compose build jupyter

# Build without cache
docker compose build --no-cache
```

**LÆ°u Ã½**: Docker compose Ä‘Ã£ Ä‘Æ°á»£c cáº¥u hÃ¬nh vá»›i live code mounting, code changes sáº½ reflect ngay láº­p tá»©c mÃ  khÃ´ng cáº§n rebuild!


## â–¶ï¸ Cháº¡y Services

### Start All Services

```bash
# Start táº¥t cáº£ services
docker compose up -d

# View logs
docker compose logs -f

# Stop services
docker compose down
```

### Start Individual Services

```bash
# Start PostgreSQL only
docker compose up -d postgres

# Start Dashboard
docker compose up -d dashboard
# Access: http://localhost:8501

# Start Jupyter
docker compose up -d jupyter
# Access: http://localhost:8888
```

### Run Pipeline

```bash
# Run pipeline manually
docker compose run --rm pipeline python scripts/run_pipeline.py

# Run vá»›i custom arguments
docker compose run --rm pipeline python scripts/run_pipeline.py \
  --orders-path data/sample/orders.csv \
  --customers-path data/sample/customers.json \
  --products-path data/sample/products.json
```

**LÆ°u Ã½**: Docker compose Ä‘Ã£ Ä‘Æ°á»£c cáº¥u hÃ¬nh vá»›i **live code mounting**:
- âœ… ToÃ n bá»™ project Ä‘Æ°á»£c mount vÃ o container
- âœ… Code changes Ä‘Æ°á»£c reflect ngay láº­p tá»©c (khÃ´ng cáº§n rebuild)
- âœ… PhÃ¹ há»£p cho development vÃ  debugging


## ğŸ“Š Services

| Service | Port | URL | Description |
|---------|------|-----|-------------|
| **Dashboard** | 8501 | http://localhost:8501 | Streamlit dashboard vá»›i BI features |
| **Jupyter** | 8888 | http://localhost:8888 | Jupyter Lab cho notebooks |
| **PostgreSQL** | 5432 | localhost:5432 | Database (user: postgres, password: etl_password) |
| **Pipeline** | - | - | ETL pipeline runner (run manually) |

## ğŸ¯ Features

### ETL Pipeline
- âœ… Extract tá»« CSV, JSON, API
- âœ… Data validation vÃ  cleaning
- âœ… Data transformation vÃ  enrichment
- âœ… Load vÃ o Data Warehouse (PostgreSQL)
- âœ… Save vÃ o Data Lake (Parquet files)
- âœ… Error handling vÃ  logging

### Dashboard
- âœ… Overview vá»›i key metrics
- âœ… Customer analytics
- âœ… Product analytics
- âœ… Sales analytics
- âœ… Pipeline status
- âœ… **Run Pipeline** page vá»›i configurable options

### Jupyter Notebooks
- âœ… Data exploration
- âœ… Custom analysis
- âœ… Visualization
- âœ… Ad-hoc queries

## ğŸ“š Documentation

- **`DOCKER.md`**: ğŸ³ Chi tiáº¿t vá» Docker setup vÃ  commands
- **`DASHBOARD_QUICKSTART.md`**: HÆ°á»›ng dáº«n sá»­ dá»¥ng Dashboard
- **`STRATEGY.md`**: Chiáº¿n lÆ°á»£c vÃ  kiáº¿n trÃºc chi tiáº¿t
- **`CHECKLIST.md`**: Checklist implementation tá»«ng phase
- **`DATA_FLOW.md`**: SÆ¡ Ä‘á»“ luá»“ng dá»¯ liá»‡u vÃ  data model

## ğŸ› ï¸ Tech Stack

- **Language**: Python 3.12
- **Data Processing**: Pandas, NumPy
- **Database**: PostgreSQL 15
- **ORM**: SQLAlchemy 2.0
- **Dashboard**: Streamlit, Plotly
- **Notebooks**: Jupyter Lab
- **Containerization**: Docker, Docker Compose
- **Orchestration**: Prefect (optional)

## ğŸ”„ Workflow

1. **Extract**: Äá»c dá»¯ liá»‡u tá»« CSV, JSON, API
2. **Save Raw**: LÆ°u raw data vÃ o data lake
3. **Validate**: Kiá»ƒm tra schema vÃ  business rules
4. **Clean**: Remove duplicates, handle nulls
5. **Transform**: Join, enrich, calculate fields
6. **Save Processed**: LÆ°u processed data vÃ o data lake
7. **Load**: Load vÃ o PostgreSQL (Data Warehouse)
8. **Analyze**: Query vÃ  visualize trÃªn Dashboard

## ğŸ› Troubleshooting

### Port Already in Use

```bash
# Check what's using the port
lsof -i :8501
lsof -i :8888
lsof -i :5432

# Change ports in docker-compose.yml
```

### Database Connection Issues

```bash
# Check if PostgreSQL is running
docker compose ps postgres

# Check logs
docker compose logs postgres

# Test connection
docker compose exec postgres pg_isready -U postgres
```

### Container Won't Start

```bash
# Check logs
docker compose logs <service_name>

# Rebuild
docker compose build --no-cache <service_name>

# Remove and recreate
docker compose down
docker compose up -d
```

Xem **`DOCKER.md`** Ä‘á»ƒ biáº¿t thÃªm troubleshooting tips.

## ğŸ“ Common Commands

```bash
# View all services status
docker compose ps

# View logs
docker compose logs -f
docker compose logs -f dashboard

# Restart service
docker compose restart dashboard

# Execute command in container
docker compose exec dashboard bash
docker compose exec postgres psql -U postgres -d etl_demo

# Stop all
docker compose down

# Stop and remove volumes (âš ï¸ deletes data)
docker compose down -v
```

## ğŸ¤ Contributing

ÄÃ¢y lÃ  project há»c táº­p, tá»± do modify vÃ  experiment!

## ğŸ“„ License

MIT

---

**Happy Data Engineering! ğŸš€**
