{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration Notebook\n",
    "\n",
    "Notebook để explore và analyze raw data trước khi đưa vào pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Add project root\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.extract import extract_csv, extract_json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Orders Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load orders\n",
    "orders = extract_csv(\"../data/sample/orders.csv\")\n",
    "\n",
    "# Basic info\n",
    "print(\"Shape:\", orders.shape)\n",
    "print(\"\\nColumns:\", orders.columns.tolist())\n",
    "print(\"\\nData types:\")\n",
    "print(orders.dtypes)\n",
    "print(\"\\nMissing values:\")\n",
    "print(orders.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Processed Data (Parquet Files)\n",
    "\n",
    "**Lưu ý**: Parquet files là binary files, không thể mở trực tiếp trong Jupyter text editor. Phải dùng pandas để đọc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load processed parquet files\n",
    "# Parquet files are binary, must use pandas to read them\n",
    "\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "processed_dir = Path(\"../data/processed\")\n",
    "parquet_files = list(processed_dir.glob(\"*.parquet\"))\n",
    "\n",
    "if parquet_files:\n",
    "    print(f\"Found {len(parquet_files)} parquet files:\")\n",
    "    for f in sorted(parquet_files):\n",
    "        print(f\"  - {f.name}\")\n",
    "    \n",
    "    # Load latest file\n",
    "    latest_file = max(parquet_files, key=lambda x: x.stat().st_mtime)\n",
    "    print(f\"\\nLoading latest: {latest_file.name}\")\n",
    "    \n",
    "    df_processed = pd.read_parquet(latest_file)\n",
    "    print(f\"Shape: {df_processed.shape}\")\n",
    "    df_processed.head()\n",
    "else:\n",
    "    print(\"No parquet files found. Run pipeline to generate processed data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data\n",
    "orders.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
