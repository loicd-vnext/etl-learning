"""
Streamlit Dashboard - ETL Pipeline Dashboard vÃ  BI
"""
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime

from src.dashboard import Dashboard
from src.utils.database import db_manager

# Page config
st.set_page_config(
    page_title="ETL Pipeline Dashboard",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Title
st.title("ğŸ“Š ETL Pipeline Dashboard")
st.markdown("---")

# Initialize dashboard
dashboard = Dashboard()

# Sidebar
st.sidebar.title("ğŸ”§ Navigation")
page = st.sidebar.selectbox(
    "Chá»n trang",
    ["ğŸš€ Run Pipeline", "ğŸ“ˆ Overview", "ğŸ‘¥ Customers", "ğŸ“¦ Products", "ğŸ’° Sales", "âš™ï¸ Pipeline Status"]
)

# Check database connection
if not db_manager.test_connection():
    st.error("âŒ KhÃ´ng thá»ƒ káº¿t ná»‘i database. Vui lÃ²ng kiá»ƒm tra database connection.")
    st.stop()

# Run Pipeline Page
if page == "ğŸš€ Run Pipeline":
    st.header("ğŸš€ Run ETL Pipeline")
    st.markdown("Cháº¡y ETL pipeline vá»›i cÃ¡c tÃ¹y chá»n tÃ¹y chá»‰nh")
    
    # Pipeline Configuration Form
    with st.form("pipeline_config"):
        st.subheader("ğŸ“‹ Pipeline Configuration")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**Data Sources**")
            orders_path = st.text_input("Orders CSV Path", value="data/sample/orders.csv")
            customers_path = st.text_input("Customers JSON Path", value="data/sample/customers.json")
            products_path = st.text_input("Products JSON Path", value="data/sample/products.json")
        
        with col2:
            st.markdown("**Pipeline Options**")
            validate_data = st.checkbox("Validate Data", value=True)
            clean_data = st.checkbox("Clean Data", value=True)
            transform_data = st.checkbox("Transform Data", value=True)
            save_to_lake = st.checkbox("Save to Data Lake", value=True)
            load_to_warehouse = st.checkbox("Load to Warehouse", value=True)
            continue_on_error = st.checkbox("Continue on Error", value=False)
        
        batch_size = st.slider("Batch Size", min_value=100, max_value=10000, value=1000, step=100)
        
        # Submit button
        run_button = st.form_submit_button("ğŸš€ Run Pipeline", type="primary", use_container_width=True)
    
    # Run pipeline when button is clicked
    if run_button:
        st.markdown("---")
        st.subheader("ğŸ“Š Pipeline Execution")
        
        # Create containers
        progress_container = st.container()
        result_container = st.container()
        
        with progress_container:
            progress_bar = st.progress(0)
            status_text = st.empty()
            log_expander = st.expander("ğŸ“ Execution Logs", expanded=True)
        
        try:
            # Import pipeline
            from src.pipeline import ETLPipeline, PipelineConfig
            import io
            import sys
            from contextlib import redirect_stdout, redirect_stderr
            
            # Create config
            config = PipelineConfig(
                orders_path=orders_path,
                customers_path=customers_path,
                products_path=products_path,
                validate_data=validate_data,
                clean_data=clean_data,
                transform_data=transform_data,
                save_to_lake=save_to_lake,
                load_to_warehouse=load_to_warehouse,
                continue_on_error=continue_on_error,
                batch_size=batch_size
            )
            
            # Update progress
            status_text.info("ğŸ”„ Initializing pipeline...")
            progress_bar.progress(5)
            
            # Create pipeline
            pipeline = ETLPipeline(config)
            
            # Capture logs
            log_output = io.StringIO()
            
            # Run pipeline with log capture
            status_text.info("ğŸ”„ Running pipeline... Please wait...")
            progress_bar.progress(10)
            
            # Run pipeline (logs will go to file, we'll read them)
            result = pipeline.run()
            
            # Update progress
            progress_bar.progress(100)
            status_text.empty()
            
            # Display results
            with result_container:
                st.markdown("---")
                st.subheader("âœ… Pipeline Execution Results")
                
                # Success/Failure banner
                if result.success:
                    st.success(f"ğŸ‰ Pipeline completed successfully in {result.duration_seconds:.2f} seconds!")
                else:
                    st.error("âŒ Pipeline failed!")
                
                # Execution Summary Cards
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    status_icon = "âœ…" if result.success else "âŒ"
                    st.metric("Status", f"{status_icon} {'Success' if result.success else 'Failed'}")
                with col2:
                    st.metric("Duration", f"{result.duration_seconds:.2f}s")
                with col3:
                    st.metric("Steps Completed", len(result.steps_completed))
                with col4:
                    st.metric("Steps Failed", len(result.steps_failed))
                
                # Steps Timeline
                st.markdown("#### ğŸ“‹ Execution Steps:")
                steps_data = []
                for i, step in enumerate(result.steps_completed, 1):
                    steps_data.append({
                        "Step": i,
                        "Name": step.replace("_", " ").title(),
                        "Status": "âœ… Completed",
                        "Time": "âœ“"
                    })
                
                for step in result.steps_failed:
                    steps_data.append({
                        "Step": len(steps_data) + 1,
                        "Name": step.replace("_", " ").title(),
                        "Status": "âŒ Failed",
                        "Time": "âœ—"
                    })
                
                if steps_data:
                    steps_df = pd.DataFrame(steps_data)
                    st.dataframe(steps_df, use_container_width=True, hide_index=True)
                
                # Statistics
                if result.statistics:
                    st.markdown("#### ğŸ“Š Statistics:")
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        if "extract" in result.statistics:
                            st.markdown("**Extract:**")
                            st.json(result.statistics["extract"])
                    
                    with col2:
                        if "transform" in result.statistics:
                            st.markdown("**Transform:**")
                            st.json(result.statistics["transform"])
                    
                    if "clean" in result.statistics:
                        st.markdown("**Clean:**")
                        st.json(result.statistics["clean"])
                
                # Errors
                if result.errors:
                    st.markdown("#### âš ï¸ Errors:")
                    for error in result.errors:
                        st.error(f"âŒ {error}")
                
                # Show log file content
                log_expander.markdown("#### Recent Logs:")
                try:
                    from pathlib import Path
                    log_dir = Path("logs")
                    if log_dir.exists():
                        log_files = sorted(log_dir.glob("*.log"), key=lambda x: x.stat().st_mtime, reverse=True)
                        if log_files:
                            with open(log_files[0], 'r', encoding='utf-8') as f:
                                lines = f.readlines()
                                # Show last 50 lines
                                recent_logs = "".join(lines[-50:])
                                log_expander.code(recent_logs, language="text")
                except Exception as e:
                    log_expander.warning(f"Could not read log file: {e}")
                
                # Action buttons
                if result.success:
                    st.markdown("---")
                    st.subheader("âš¡ Next Actions")
                    col1, col2 = st.columns(2)
                    with col1:
                        if st.button("ğŸ”„ Refresh All Data", key="refresh_after_run", use_container_width=True):
                            st.rerun()
                    with col2:
                        st.info("ğŸ’¡ Sá»­ dá»¥ng sidebar Ä‘á»ƒ xem Overview, Sales, hoáº·c cÃ¡c pages khÃ¡c")
        
        except Exception as e:
            progress_bar.progress(100)
            status_text.error("âŒ Pipeline execution failed")
            st.error(f"**Error:** {str(e)}")
            import traceback
            with st.expander("ğŸ” Error Details", expanded=False):
                st.code(traceback.format_exc(), language="python")
    
    # Show last pipeline run info
    st.markdown("---")
    st.subheader("â„¹ï¸ Pipeline Information")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        **Pipeline Steps:**
        1. ğŸ“¥ **Extract** - Äá»c dá»¯ liá»‡u tá»« CSV, JSON
        2. ğŸ’¾ **Save Raw Data** - LÆ°u raw data vÃ o data lake
        3. âœ… **Validate** - Kiá»ƒm tra data quality
        4. ğŸ§¹ **Clean** - LÃ m sáº¡ch data
        5. ğŸ”„ **Transform** - Transform vÃ  enrich data
        6. ğŸ’¾ **Save Processed** - LÆ°u processed data
        7. ğŸ“Š **Load to Warehouse** - Load vÃ o database
        """)
    
    with col2:
        st.markdown("""
        **Configuration Options:**
        - âœ… **Validate Data**: Kiá»ƒm tra schema vÃ  business rules
        - ğŸ§¹ **Clean Data**: Remove duplicates, handle nulls
        - ğŸ”„ **Transform Data**: Join, enrich, calculate
        - ğŸ’¾ **Save to Lake**: LÆ°u raw vÃ  processed data
        - ğŸ“Š **Load to Warehouse**: Load vÃ o PostgreSQL
        - âš ï¸ **Continue on Error**: Tiáº¿p tá»¥c khi cÃ³ lá»—i
        """)
    
    # Quick actions
    st.markdown("---")
    st.subheader("âš¡ Quick Actions")
    st.info("ğŸ’¡ Sá»­ dá»¥ng sidebar dropdown á»Ÿ trÃªn Ä‘á»ƒ chuyá»ƒn giá»¯a cÃ¡c pages: Overview, Customers, Products, Sales, Pipeline Status")

# Overview Page
elif page == "ğŸ“ˆ Overview":
    st.header("ğŸ“ˆ Tá»•ng Quan")
    
    # Get statistics
    stats = dashboard.get_pipeline_stats()
    
    if stats["database_connected"]:
        # Key Metrics
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ğŸ“Š Total Records", f"{stats['total_records']:,}")
        
        with col2:
            table_count = len(stats["tables"])
            st.metric("ğŸ—„ï¸ Tables", table_count)
        
        with col3:
            if stats["tables"].get("fact_sales"):
                sales_count = stats["tables"]["fact_sales"]["row_count"]
                st.metric("ğŸ’° Sales Records", f"{sales_count:,}")
            else:
                st.metric("ğŸ’° Sales Records", "0")
        
        with col4:
            if stats["last_update"]:
                st.metric("ğŸ• Last Update", "Connected")
            else:
                st.metric("ğŸ• Last Update", "N/A")
        
        st.markdown("---")
        
        # Table Statistics
        st.subheader("ğŸ“‹ Table Statistics")
        table_data = []
        for table_name, table_info in stats["tables"].items():
            table_data.append({
                "Table": table_name,
                "Row Count": table_info["row_count"]
            })
        
        if table_data:
            df_tables = pd.DataFrame(table_data)
            st.dataframe(df_tables, use_container_width=True)
        
        # Sales Summary
        st.subheader("ğŸ’° Sales Summary")
        sales_summary = dashboard.get_sales_summary()
        if not sales_summary.empty and sales_summary['total_orders'].iloc[0] > 0:
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Total Orders", f"{int(sales_summary['total_orders'].iloc[0]):,}")
            with col2:
                st.metric("Total Revenue", f"${sales_summary['total_revenue'].iloc[0]:,.2f}")
            with col3:
                st.metric("Avg Order Value", f"${sales_summary['avg_order_value'].iloc[0]:,.2f}")
            with col4:
                st.metric("Total Discount", f"${sales_summary['total_discount'].iloc[0]:,.2f}")
        else:
            st.info("ğŸ’¡ No sales data available. Run pipeline to load data: `python scripts/run_pipeline.py`")
        
        # Customer & Product Summary
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ‘¥ Customer Summary")
            customer_summary = dashboard.get_customer_summary()
            if not customer_summary.empty:
                st.metric("Total Customers", f"{int(customer_summary['total_customers'].iloc[0]):,}")
                st.metric("Cities", f"{int(customer_summary['cities'].iloc[0]):,}")
                st.metric("Countries", f"{int(customer_summary['countries'].iloc[0]):,}")
        
        with col2:
            st.subheader("ğŸ“¦ Product Summary")
            product_summary = dashboard.get_product_summary()
            if not product_summary.empty:
                st.metric("Total Products", f"{int(product_summary['total_products'].iloc[0]):,}")
                st.metric("Categories", f"{int(product_summary['categories'].iloc[0]):,}")
                st.metric("Brands", f"{int(product_summary['brands'].iloc[0]):,}")
                st.metric("Avg Price", f"${product_summary['avg_price'].iloc[0]:,.2f}")

# Customers Page
elif page == "ğŸ‘¥ Customers":
    st.header("ğŸ‘¥ Customer Analytics")
    
    # Top Customers
    st.subheader("ğŸ† Top Customers by Revenue")
    top_customers = dashboard.get_top_customers(limit=10)
    
    if not top_customers.empty:
        # Display table
        st.dataframe(top_customers, use_container_width=True)
        
        # Chart
        if len(top_customers) > 0 and 'total_revenue' in top_customers.columns:
            fig = px.bar(
                top_customers.head(10),
                x='customer_name',
                y='total_revenue',
                title="Top 10 Customers by Revenue",
                labels={'customer_name': 'Customer', 'total_revenue': 'Revenue ($)'}
            )
            fig.update_xaxes(tickangle=45)
            st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("No customer data available")

# Products Page
elif page == "ğŸ“¦ Products":
    st.header("ğŸ“¦ Product Analytics")
    
    # Top Products
    st.subheader("ğŸ† Top Products by Sales")
    top_products = dashboard.get_top_products(limit=10)
    
    if not top_products.empty:
        # Display table
        st.dataframe(top_products, use_container_width=True)
        
        # Chart
        if len(top_products) > 0 and 'total_revenue' in top_products.columns:
            fig = px.bar(
                top_products.head(10),
                x='product_name',
                y='total_revenue',
                title="Top 10 Products by Revenue",
                labels={'product_name': 'Product', 'total_revenue': 'Revenue ($)'}
            )
            fig.update_xaxes(tickangle=45)
            st.plotly_chart(fig, use_container_width=True)
    
    # Category Performance
    st.subheader("ğŸ“Š Category Performance")
    category_perf = dashboard.get_category_performance()
    
    if not category_perf.empty:
        st.dataframe(category_perf, use_container_width=True)
        
        if len(category_perf) > 0 and 'total_revenue' in category_perf.columns:
            fig = px.pie(
                category_perf,
                values='total_revenue',
                names='category',
                title="Revenue by Category"
            )
            st.plotly_chart(fig, use_container_width=True)

# Sales Page
elif page == "ğŸ’° Sales":
    st.header("ğŸ’° Sales Analytics")
    
    # Daily Sales
    st.subheader("ğŸ“ˆ Daily Sales Trend")
    daily_sales = dashboard.get_daily_sales()
    
    if not daily_sales.empty and 'date' in daily_sales.columns and len(daily_sales) > 0:
        # Line chart
        fig = px.line(
            daily_sales,
            x='date',
            y='total_revenue',
            title="Daily Sales Revenue",
            labels={'date': 'Date', 'total_revenue': 'Revenue ($)'},
            markers=True
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # Display data
        st.dataframe(daily_sales, use_container_width=True)
    else:
        st.info("No daily sales data available. Run pipeline to load data.")
    
    # Sales Summary
    st.subheader("ğŸ“Š Sales Summary")
    sales_summary = dashboard.get_sales_summary()
    if not sales_summary.empty:
        st.dataframe(sales_summary, use_container_width=True)

# Pipeline Status Page
elif page == "âš™ï¸ Pipeline Status":
    st.header("âš™ï¸ Pipeline Status")
    
    stats = dashboard.get_pipeline_stats()
    
    if stats["database_connected"]:
        st.success("âœ… Database Connected")
        
        # Table Status
        st.subheader("ğŸ“‹ Table Status")
        for table_name, table_info in stats["tables"].items():
            col1, col2 = st.columns([3, 1])
            with col1:
                st.write(f"**{table_name}**")
            with col2:
                st.metric("Rows", f"{table_info['row_count']:,}")
        
        # Connection Info
        st.subheader("ğŸ”Œ Connection Info")
        st.info(f"Last Update: {stats.get('last_update', 'N/A')}")
        st.info(f"Total Records: {stats['total_records']:,}")
    else:
        st.error("âŒ Database Not Connected")

# Footer
st.markdown("---")
st.markdown("**ETL Pipeline Dashboard** | Built with Streamlit")

